model:
  hidden_dim: 128
  num_heads: 4
  num_layers: 3

training:
  batch_size: 512
  learning_rate: 0.0005
  num_epochs: 200

data:
  min_citations: 5
  min_year: 2015 